{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Home](http://realai.org/) > [Course](http://realai.org/course/) > [TensorFlow](http://realai.org/course/tensorflow/) > [GPU](http://realai.org/course/tensorflow/#gpu) >\n",
    "\n",
    "# Deep CNN for CIFAR-10\n",
    "\n",
    "*Last Updated: September 1, 2017*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a [NVIDIA® Tesla® K80](http://www.nvidia.com/object/tesla-k80.html) GPU, the convolutional neural network (CNN) built in the [last session](http://realai.org/course/tensorflow/#deep-models) for [MNIST handwritten digits](http://yann.lecun.com/exdb/mnist/) trains in less than 2 minutes. Let's use the GPU for a harder dataset called [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html), which again contains 60000 images, divided into a 50000-image training set and a 10000-image test set, with exactly 10 class labels: airplane, automobile, bird, cat, deer, dog, frog, horse, ship and truck. The following tech report describes it in more details:\n",
    "\n",
    "* 2009 April 8, Alex Krizhevsky. [Learning Multiple Layers of Features from Tiny Images](https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf).\n",
    "\n",
    "What's more difficult than the MNIST images is that the CIFAR-10 data are 32x32 color images. Moreover, we cannot load the data as easily as before, and need to a bit of extra work. First we manually [download](https://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz) the binary version of the dataset, then store and unpack it in a persistent directory. Here we use `CIFAR_10_data/`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR_10_data/:\r\n",
      "\u001b[0m\u001b[01;34mcifar-10-batches-bin\u001b[0m/  \u001b[01;31mcifar-10-binary.tar.gz\u001b[0m\r\n",
      "\r\n",
      "CIFAR_10_data/cifar-10-batches-bin:\r\n",
      "batches.meta.txt  data_batch_2.bin  data_batch_4.bin  readme.html\r\n",
      "data_batch_1.bin  data_batch_3.bin  data_batch_5.bin  test_batch.bin\r\n"
     ]
    }
   ],
   "source": [
    "%ls -R CIFAR_10_data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the CIFAR-10 dataset has a similar structure to MNIST, we intend to load it into our program in a way that it can be used just as the \"MNIST\" dataset in the previous [exercise](http://nbviewer.jupyter.org/url/realai.org/course/tensorflow/solving-MNIST-by-convolution.ipynb), with more interesting images. For that we import the modules `base` and `mnist`. We also need `numpy` and `os` for data processing. Finally we define some constants in capital letters, including LOGDIR for tf.summary.FileWriter and TensorBoard to use later, and put them below so that they're easier to find:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.contrib.learn.python.learn.datasets import base\n",
    "from tensorflow.contrib.learn.python.learn.datasets import mnist\n",
    "\n",
    "DATA_DIR = \"CIFAR_10_data/cifar-10-batches-bin\"\n",
    "LOGDIR = \"/tmp/CIFAR_10\"\n",
    "VALIDATION_SIZE = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next two cells define functions to process the data files. The first function parses a single CIFAR-10 data file. The second function combines the outputs from the first function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_cifar10_one_file(filename):\n",
    "  \"\"\"Reads and parses examples from CIFAR-10 data files\n",
    "  \n",
    "  Args:\n",
    "    filename: A string of the name of the data file to read from\n",
    "\n",
    "  Returns:\n",
    "    images: 4D numpy.uint8 array of size [num_samples, height (32), width (32), depth (3)]\n",
    "    labels: 1D numpy.float64 array of [num_samples] size\n",
    "  \"\"\"\n",
    "  \n",
    "  with open(filename, 'rb') as f:\n",
    "    data = f.read()\n",
    "  data = np.frombuffer(data, dtype=np.uint8)\n",
    "  data = data.reshape(10000, 3073)\n",
    "  labels, images = np.split(data, (1,), axis=1)\n",
    "  \n",
    "  images = images.reshape(10000, 3, 32, 32)\n",
    "  images = np.transpose(images, (0, 2, 3, 1))\n",
    "  \n",
    "  num_samples = labels.shape[0]\n",
    "  one_hot = np.zeros((num_samples, 10))\n",
    "  one_hot.flat[np.arange(num_samples)*10 + labels.ravel()] = 1\n",
    "  \n",
    "  return images, one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_cifar10_files(data_dir, test_data=False):\n",
    "  \"\"\"Combine CIFAR-10 data using returns from function read_cifar10_one_file\n",
    "  \n",
    "  Args:\n",
    "    data_dir: Path to the CIFAR-10 data directory\n",
    "    test_data: bool, indicating if one should use the train or test data file\n",
    "\n",
    "  Return: (same as read_cifar10_one_file)\n",
    "    images: 4D numpy.uint8 array of size [num_samples, height (32), width (32), depth (3)]\n",
    "    labels: 1D numpy.float64 array of [num_samples] size\n",
    "  \"\"\"\n",
    "  if not test_data:\n",
    "    filenames = [os.path.join(data_dir, 'data_batch_%d.bin' % i)\n",
    "                 for i in range(1, 6)]\n",
    "  else:\n",
    "    filenames = [os.path.join(data_dir, 'test_batch.bin')]\n",
    "\n",
    "  images = np.empty((0, 32, 32, 3), dtype=np.uint8)\n",
    "  labels = np.empty((0, 10), dtype=np.float64)\n",
    "\n",
    "  for f in filenames:\n",
    "    if not tf.gfile.Exists(f):\n",
    "      raise ValueError('Failed to find file: ' + f)\n",
    "    data = read_cifar10_one_file(f)\n",
    "    images = np.concatenate((images, data[0]))\n",
    "    labels = np.concatenate((labels, data[1]))\n",
    "\n",
    "  return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these two helper functions, we can feed the data into a \"Datasets\" object called \"CIFAR\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images, labels = read_cifar10_files(DATA_DIR)\n",
    "validation = mnist.DataSet(images[:VALIDATION_SIZE], labels[:VALIDATION_SIZE], reshape=False)\n",
    "train = mnist.DataSet(images[VALIDATION_SIZE:], labels[VALIDATION_SIZE:], reshape=False)\n",
    "\n",
    "images, labels = read_cifar10_files(DATA_DIR, test_data=True)\n",
    "test = mnist.DataSet(images, labels, reshape=False)\n",
    "\n",
    "CIFAR = base.Datasets(train=train, validation=validation, test=test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's possible to follow almost exactly the steps for MNIST, noting a few differences: (1) the CIFAR-10 images are already in shape (batch_size, 32, 32, 3), we no longer need the `tf.reshape` operation; (2) after two rounds of max pooling, the resulting tensor is in shape (batch_size, 8, 8, 64) and should be reshaped into 8*8*64 instead of 7*7*64; and (3) change the old variable name \"MNIST\" to \"CIFAR\"! At this point, if we ran this experiment using the MNIST model, it would again train in around 2 minutes but the validation error should be around 30%!\n",
    "\n",
    "Only a little bit of extra work is needed to build a better model. We know that sometimes the construct of two successive 3x3 convnet layers followed by a max pooling layer can improve model performance. Such a style is referred to as \"VGG\", based on research from the following paper:\n",
    "\n",
    "* 2015 April 11, Karen Simonyan and Andrew Zisserman. [Very Deep Convolutional Networks for Large-Scale Image Recognitio\n",
    "n](https://arxiv.org/abs/1409.1556). *arXiv:1409.1556*.\n",
    "\n",
    "The next cell contains extra convolution and max pooling layers to build a deep CNN in VGG style:\n",
    "\n",
    "![](http://realai.org/course/tensorflow/deep-cnn-for-CIFAR-10-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start with CIFAR-10 input\n",
    "images = tf.placeholder(tf.float32, (None, 32, 32, 3), name=\"Images\")\n",
    "\n",
    "# A regularizer to be added to all conv layers\n",
    "regularizer = tf.contrib.layers.l2_regularizer(scale=0.1)\n",
    "\n",
    "# Add two convolution layers with max pooling\n",
    "conv1_1 = tf.layers.conv2d(\n",
    "  images, 32, 3, padding=\"same\", activation=tf.nn.relu, kernel_regularizer=regularizer,\n",
    "  name=\"Conv1_1\")\n",
    "conv1_2 = tf.layers.conv2d(\n",
    "  conv1_1, 32, 3, padding=\"same\", activation=tf.nn.relu, kernel_regularizer=regularizer,\n",
    "  name=\"Conv1_2\")\n",
    "pool1 = tf.layers.max_pooling2d(conv1_2, 2, 2, name=\"Pool1\")\n",
    "\n",
    "conv2_1 = tf.layers.conv2d(\n",
    "  pool1, 64, 3, padding=\"same\", activation=tf.nn.relu, kernel_regularizer=regularizer,\n",
    "  name=\"Conv2_1\")\n",
    "conv2_2 = tf.layers.conv2d(\n",
    "  conv2_1, 64, 3, padding=\"same\", activation=tf.nn.relu, kernel_regularizer=regularizer,\n",
    "  name=\"Conv2_2\")\n",
    "pool2 = tf.layers.max_pooling2d(conv2_2, 2, 2, name=\"Pool2\")\n",
    "\n",
    "# Add another conv\n",
    "conv3_1 = tf.layers.conv2d(\n",
    "  pool2, 128, 3, padding=\"same\", activation=tf.nn.relu, kernel_regularizer=regularizer,\n",
    "  name=\"Conv3_1\")\n",
    "conv3_2 = tf.layers.conv2d(\n",
    "  conv3_1, 128, 3, padding=\"same\", activation=tf.nn.relu, kernel_regularizer=regularizer,\n",
    "  name=\"Conv3_2\")\n",
    "pool3 = tf.layers.max_pooling2d(conv3_2, 2, 2, name=\"Pool3\")\n",
    "\n",
    "# Reshape the 2D tensor back to 1D to be fed into \"Dense\"\n",
    "pool3_flat = tf.reshape(pool3, (-1, 4*4*128), name=\"Pool3_Flat\")\n",
    "\n",
    "# Two dense layers with one dropout\n",
    "# dense0 = tf.layers.dense(pool2_flat, 384, activation=tf.nn.relu, name=\"Dense0\")\n",
    "dense = tf.layers.dense(pool3_flat, 512, activation=tf.nn.relu, name=\"Dense\")\n",
    "keep_prob = tf.placeholder(tf.float32, name=\"Keep_Probability\")\n",
    "dropout = tf.nn.dropout(dense, keep_prob, name=\"Dropout\")\n",
    "\n",
    "# The original dense layer to compute logits that are later used for classification\n",
    "logits = tf.layers.dense(dropout, 10, activation=None, name=\"Logits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training and test, we simply follow the MNIST exercise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A few more tensors for training and reporting\n",
    "labels = tf.placeholder(tf.float32, (None, 10), name=\"Labels\")\n",
    "\n",
    "with tf.name_scope(\"Loss\"):\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=logits),\n",
    "        name=\"Mean\")\n",
    "\n",
    "with tf.name_scope(\"Optimizer\"):\n",
    "    train = tf.train.AdamOptimizer(learning_rate=0.001, name=\"Adam\").minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"Error\"):\n",
    "    error = tf.reduce_mean(\n",
    "        tf.cast(tf.not_equal(tf.argmax(labels, 1), tf.argmax(logits, 1)), tf.float32), name=\"Mean\")\n",
    "\n",
    "tf.summary.image(\"Images\", images, max_outputs=4)\n",
    "tf.summary.scalar(\"Loss\", loss)\n",
    "tf.summary.scalar(\"Error\", error)\n",
    "summ = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Session, FileWriter and variable initialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if tf.gfile.Exists(LOGDIR):\n",
    "    tf.gfile.DeleteRecursively(LOGDIR)\n",
    "tf.gfile.MakeDirs(LOGDIR)\n",
    "\n",
    "sess = tf.Session()\n",
    "writer = tf.summary.FileWriter(LOGDIR, sess.graph)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full training using a cloud [GPU](https://cloud.google.com/compute/pricing#gpus) on an n1-standard-2 (2 vCPUs, 7.2 GB memory) machine should take less than 10 minutes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Training loss is 2.30075, error is 87.50%\n",
      "Step 500: Training loss is 1.02283, error is 35.16%\n",
      "Step 1000: Training loss is 0.86207, error is 30.47%\n",
      "Step 1500: Training loss is 0.59323, error is 21.88%\n",
      "Step 2000: Training loss is 0.50439, error is 19.53%\n",
      "Step 2500: Training loss is 0.26510, error is 9.38%\n",
      "Step 3000: Training loss is 0.29858, error is 7.81%\n",
      "Step 3500: Training loss is 0.24689, error is 8.59%\n",
      "Step 4000: Training loss is 0.18905, error is 9.38%\n",
      "Step 4500: Training loss is 0.13786, error is 3.91%\n",
      "Step 5000: Training loss is 0.11263, error is 3.91%\n",
      "Step 5500: Training loss is 0.07144, error is 1.56%\n",
      "Step 6000: Training loss is 0.03573, error is 0.00%\n",
      "Step 6500: Training loss is 0.06624, error is 1.56%\n",
      "Step 7000: Training loss is 0.07402, error is 2.34%\n",
      "Step 7500: Training loss is 0.05901, error is 2.34%\n",
      "Step 8000: Training loss is 0.06364, error is 3.12%\n",
      "Step 8500: Training loss is 0.03966, error is 1.56%\n",
      "Step 9000: Training loss is 0.01623, error is 0.00%\n",
      "Step 9500: Training loss is 0.07730, error is 1.56%\n",
      "CPU times: user 4min 52s, sys: 59.8 s, total: 5min 52s\n",
      "Wall time: 7min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(10000):\n",
    "    batch = CIFAR.train.next_batch(128)\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        Error, Loss, Summ = sess.run((error, loss, summ), feed_dict={images: batch[0], labels: batch[1], keep_prob: 1.0})\n",
    "        writer.add_summary(Summ, i)\n",
    "        \n",
    "        if i % 500 == 0:\n",
    "            print(\"Step {}: Training loss is {:.5f}, error is {:.2f}%\".format(i, Loss, Error * 100))\n",
    "\n",
    "    sess.run(train, feed_dict={images: batch[0], labels: batch[1], keep_prob: 0.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the validation and test result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation error is 20.30%\n"
     ]
    }
   ],
   "source": [
    "Error = sess.run(error, feed_dict={images: CIFAR.validation.images, labels: CIFAR.validation.labels, keep_prob: 1.0})\n",
    "print(\"Validation error is {:.2f}%\".format(Error * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error is 21.27%\n"
     ]
    }
   ],
   "source": [
    "Error = sess.run(error, feed_dict={images: CIFAR.test.images, labels: CIFAR.test.labels, keep_prob: 1.0})\n",
    "print(\"Test error is {:.2f}%\".format(Error * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our test and validation errors are fairly close, but a lot higher than the training error, which suggests that our model [overfits](https://en.wikipedia.org/wiki/Overfitting). General strategies to reduce overfitting include getting more training data and designing simpler models. They're outside the scope of this exercise and will be covered elsewhere.\n",
    "\n",
    "Close FileWriter and Session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer.close()\n",
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
