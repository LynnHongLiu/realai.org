---
permalink: /safety/oracle-ai/
title: Safety | Oracle AI
---
# Oracle AI

An Oracle AI ([Armstrong et al., 2012](https://link.springer.com/article/10.1007/s11023-012-9282-2)), or *oracle*, is an AI system that doesn't act in the real world except by answering questions. Although it can only physically affect the world through its users, these users are vulnerable to manipulation if the oracle is superintelligent ([Bostrom, 2014](https://www.amazon.com/Superintelligence-Dangers-Strategies-Nick-Bostrom/dp/0199678111)).

An oracle is called *domain-specific* if it is only queried for domain-specific tasks, e.g. [theorem proving](http://realai.org/automated-theorem-proving/). Motivated by the possibility that deficiencies in domain-specific AIs might be exploited by a larger AI system to manipulate its users, [Sarma & Hay (2017)](https://arxiv.org/abs/1708.02553) suggest possible lines of research and software projects within the scope to domain-specific oracles that perform mathematical computations.

## References

* 2017, Stuart Armstrong. Value and policy networks as Oracle AIs. *in preparation*.
* 2017 August 9, Gopal P. Sarma and Nick J. Hay. [Robust Computer Algebra, Theorem Proving, and Oracle AI](https://arxiv.org/abs/1708.02553). *arXiv:1708.02553*.
* 2014 September 3, Nick Bostrom. [Superintelligence: Paths, Dangers, Strategies](https://www.amazon.com/Superintelligence-Dangers-Strategies-Nick-Bostrom/dp/0199678111). *Oxford University Press*.
* 2012 November, Stuart Armstrong, Anders Sandberg, and Nick Bostrom. [Thinking Inside the Box: Controlling and Using an Oracle AI](https://link.springer.com/article/10.1007/s11023-012-9282-2). *Minds and Machines*, 22(4):299-324. [PDF](https://nickbostrom.com/papers/oracle.pdf).

