---
permalink: /forecasts/proving-mathematical-theorems/
redirect_from: /forecasts/ATP/
title: Forecasts | Proving Mathematical Theorems
---
# Proving Mathematical Theorems

We [forecast](http://realai.org/forecasts/) that there will be an AI-generated formal proof of a difficult mathematical theorem by July 19, 2021, with a 90% confidence interval of ± 12 months.

*Last Updated: August 3, 2017*

Attainment of this milestone involves building a proof that logically connects the assumptions and conclusion of a difficult math theorem. The proof, assumptions and conclusion can all be encoded in a formal math system, like the ones used by existing [proof assistants](https://en.wikipedia.org/wiki/Proof_assistant). An AI-generated proof must be easily verifiable to be correct, but it doesn’t necessarily improve our understanding of mathematics because it might be difficult to distill the mathematical ideas behind those formal statements. Consequently, such a proof may not be publishable in top mathematical journals today, which is a requirement for the “Math Research” milestone described in [Grace et al. (2017)](https://arxiv.org/abs/1705.08807). Our task is significantly easier as the AI prover doesn’t need to understand mainstream mathematical literature, which likely requires substantial background knowledge or common sense, itself a milestone to be achieved. In fact, the AI prover doesn’t need to have any natural language processing (NLP) ability at all.

The basis of our forecast is the expectation of rapid progress in neural [reasoning](http://realai.org/reasoning/), the development of [deep learning](https://en.wikipedia.org/wiki/Deep_learning) algorithms and architectures that capture the essence of human reasoning. Since the ability to prove mathematical theorems is one aspect of reasoning, we see [automated theorem proving](http://realai.org/automated-theorem-proving/) (ATP) as a significant demonstration of progress similar to [AlphaGo](https://deepmind.com/research/alphago/) ([Silver & Huang et al., 2016](http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html)), the computer system that plays the ancient Chinese game of [Go](https://en.wikipedia.org/wiki/Go_(game)). It achieves superhuman performance by innovatively applying advanced deep learning methods to a classical Go-playing framework, but is not a core deep learning development itself, in the sense that AlphaGo is not a necessary component of an [AGI](https://en.wikipedia.org/wiki/Artificial_general_intelligence) system, because an intelligent person doesn’t need to know anything about Go. Such a person doesn’t need to know any advanced mathematics either, so we similarly view ATP not as a core deep learning discovery, but mostly an engineering project in the future that validates the progress in neural reasoning.

Since 2012, deep learning has enjoyed phenomenal success in solving cognitive tasks such as image classification, speech recognition, translation, and game playing. Remarkably, it is achieved without explicit understanding of how these tasks are solved by humans. Instead of being given explicit instructions to solve these tasks, AI systems learn highly effective solutions from data. This is driven by key advances in deep learning, many of which are inspired by neuroscience ([Hassabis et al., 2017](http://www.cell.com/neuron/fulltext/S0896-6273(17)30509-3)), despite the fact that neuroscience remains very far from a transparent theory of intelligence. Unless there is a compelling argument that reasoning is fundamentally different from other cognitive functions, for example evidence that reasoning involves an intracellular computing mechanism in neurons not used for vision, we take the [Prosaic AI](http://realai.org/prosaic/) view that a highly effective reasoning system can be built with existing methodologies, including currently unknown algorithms and architectures to be discovered along the normal path of progress within the realm of deep learning, but not a conceptually new field like [quantum mind](https://en.wikipedia.org/wiki/Quantum_mind).

More precisely, within our expectation there can be potential innovations comparable to convolutional neural networks for image recognition, recurrent neural networks for sequence-to-sequence modelling, or training on auxiliary tasks for playing games, but not a conceptual leap like the idea to apply deep architectures to reinforcement learning, as the research community is already aware of deep learning’s promise in reasoning and particularly in mathematical reasoning. For example, in a [reddit AMA session](https://www.reddit.com/r/MachineLearning/comments/25lnbt/ama_yann_lecun/) in 2014, Facebook’s Director of AI Research [Yann LeCun](http://yann.lecun.com/) mentioned reasoning multiple times as an important area in deep learning. Based on our research of online sources, he later added that [“We are attempting to replace symbols by vectors so we can replace logic by algebra.”](https://www.reddit.com/r/MachineLearning/comments/40urfy/eli25_we_are_attempting_to_replace_symbols_by/) during an [NYU symposium](http://cds.nyu.edu/ai/?pass=CfLjizw47) in January 11-13, 2016. On a podcast posted on July 21, 2017, [OpenAI](http://realai.org/research-groups/openai/)’s research scientist Dario Amodei said that [“there maybe ways in which we combine neural nets for formal reasoning.”](https://80000hours.org/2017/07/podcast-the-world-needs-ai-researchers-heres-how-to-become-one/) Two days later, [Hang Li](http://www.hangli-hl.com/index.html), the director of [Noah’s Ark Lab](http://www.noahlab.com.hk/) of Huawei Technologies, gave a talk in Beijing titled Toward Neural Symbolic Reasoning ([Chinese transcript](https://www.leiphone.com/news/201707/HgOvtgwB08zJcCTf.html)).

Several subjects related to ATP are already active areas of deep learning research. In October 2016, [DeepMind](http://realai.org/research-groups/deepmind/) demonstrated a differentiable neural computer ([Graves & Wayne et al., 2016](http://www.nature.com/nature/journal/v538/n7626/abs/nature20101.html)) capable of answering questions designed to mimic aspects of reasoning, illustrating how deep learning uses an external memory. In April 2017, a team of Berkeley researchers implemented recursion using neural architectures ([Cai et al., 2017](https://arxiv.org/abs/1704.06611)), a step towards generating more sophisticated programs. It relates to ATP as a formal proof is essentially a computer program. In May, [Rocktäschel & Riedel (2017)](https://arxiv.org/abs/1705.11040) introduced Neural Theorem Provers for end-to-end differentiable theorem proving and tested them on knowledge bases, with an interest in applying them to ATP in the future. On July 12, DeepMind researchers [Higgins et al. (2017)](https://arxiv.org/abs/1707.03389) trained a model to combine learned concepts using logical operators similar to AND, OR and NOT.

Direct attempts at applying deep learning to ATP have also emerged. Less than seven months after the publication of AlphaGo in January, [Whalen (2016)](https://arxiv.org/abs/1608.02644) adapted its tree exploration techniques to create a complete ATP system for [Metamath](http://realai.org/metamath/) propositions, with limited success. On July 19, DeepMind researchers [Pascanu & Li et al. (2017)](https://arxiv.org/abs/1707.06170) introduced algorithms that potentially could learn more flexible tree exploration strategies. Concurrently, between [Google Research](https://research.google.com/) and several universities, a collaboration project [DeepMath](https://github.com/tensorflow/deepmath) seeks to improve ATP using deep learning techniques. It is under active development as of [July 2017](https://github.com/tensorflow/deepmath/commit/7d3cea97d4545eacb8b43afab187e60ee957ebd0) and has already resulted in at least one paper ([Kaliszyk et al., 2017](https://arxiv.org/abs/1703.00426)). Anima Anandkumar, a deep learning scientist who [joined Amazon in November 2016](https://aws.amazon.com/blogs/ai/in-the-research-spotlight-anima-anandkumar/), [suggested in a July 30, 2017 tweet](https://twitter.com/AnimaAnandkumar/status/891408224020070401) that a paper modelling math functions using [LSTM](https://en.wikipedia.org/wiki/Long_short-term_memory) (Long Short-Term Memory; [Hochreiter & Schmidhuber, 1997](http://www.mitpressjournals.org/doi/abs/10.1162/neco.1997.9.8.1735)) was submitted for review at [NIPS](https://nips.cc/Conferences/2017), or Neural Information Processing Systems, a prestigious academic conference to be held in December 2017.

As the subjects of machine perception get more mature, we see a clear tendency that deep learning researchers are setting their sights on more abstract problems, with advances in reasoning, memory, and program induction particularly useful for a substantial application to ATP. On the other hand, there are no obvious commercial applications of an advanced AI prover, so we expect efforts devoted to this topic to be much less than self-driving cars. We peg the speed of progress in ATP to be roughly similar to that of computer poker, mainly driven by academic interests, and to some degree accelerated by industry sponsorship. Since ATP likely depends on innovative progress in algorithms and architectures, it is more difficult than [Multi-Player No-Limit Poker](http://realai.org/forecasts/#multi-player-no-limit-poker), which we forecast to be reached in 2019. It’s also significantly easier than AGI, as ATP is only one aspect of reasoning, which is in turn one of the many skills required for AGI. For now, we use the public forecast from a reputable authority in deep learning to estimate the year of AGI. [IDSIA](http://www.idsia.ch/)’s [Jürgen Schmidhuber](http://people.idsia.ch/~juergen/) predicted in January 2017 ([video](https://youtu.be/V0aXMTpZTfc?t=6m54s)) that AGI would be created around 2028. Because ATP is much closer to poker than to AGI, we take a leap of faith here and *speculate* that a major mathematical theorem will be proved by an AI system by **July 19, 2021**, 4 years after the most recent date in the [References](#references) section below, with a **90% confidence interval of ± 12 months** to account for higher uncertainty of future discoveries that are still unknown.

## References

* 2017 July 19, Razvan Pascanu, Yujia Li, Oriol Vinyals, Nicolas Heess, Lars Buesing, Sebastien Racanière, David Reichert, Théophane Weber, Daan Wierstra, and Peter Battaglia. [Learning model-based planning from scratch](https://arxiv.org/abs/1707.06170). *arXiv:1707.06170*. [video](https://drive.google.com/open?id=0B3u8dCFTG5iVaUxzbzRmNldGcU0). [blog](https://deepmind.com/blog/agents-imagine-and-plan/).
* 2017 July 19, Demis Hassabis, Dharshan Kumaran, Christopher Summerfield, and Matthew Botvinick. [Neuroscience-Inspired Artificial Intelligence](http://www.cell.com/neuron/fulltext/S0896-6273(17)30509-3). *Neuron*, 95(2):245-258. [interview](https://www.theverge.com/2017/7/19/15998610/ai-neuroscience-machine-learning-deepmind-demis-hassabis-interview). [blog](https://deepmind.com/blog/ai-and-neuroscience-virtuous-circle/).
* 2017 July 12, Irina Higgins, Nicolas Sonnerat, Loic Matthey, Arka Pal, Christopher P Burgess, Matthew Botvinick, Demis Hassabis, and Alexander Lerchner. [SCAN: Learning Abstract Hierarchical Compositional Visual Concepts](https://arxiv.org/abs/1707.03389). *arXiv:1707.03389*. [blog](https://deepmind.com/blog/imagine-creating-new-visual-concepts-recombining-familiar-ones/).
* 2017 May 31, Tim Rocktäschel and Sebastian Riedel. [End-to-end Differentiable Proving](https://arxiv.org/abs/1705.11040). *arXiv:1705.11040*.
* 2017 May 30, Katja Grace, John Salvatier, Allan Dafoe, Baobao Zhang, and Owain Evans. [When Will AI Exceed Human Performance? Evidence from AI Experts](https://arxiv.org/abs/1705.08807). *arXiv:1705.08807*.
* 2017 April 21, Jonathon Cai, Richard Shin, and Dawn Song. [Making Neural Programming Architectures Generalize via Recursion](https://arxiv.org/abs/1704.06611). *arXiv:1704.06611*.
* 2017 March 1, Cezary Kaliszyk, François Chollet, and Christian Szegedy. [HolStep: A Machine Learning Dataset for Higher-order Logic Theorem Proving](https://arxiv.org/abs/1703.00426). *arXiv:1703.00426*. [code](https://github.com/tensorflow/deepmath/tree/master/deepmath/holstep_baselines). [site](http://cl-informatik.uibk.ac.at/cek/holstep/).
* 2016 October 12, Alex Graves, Greg Wayne, Malcolm Reynolds, Tim Harley, Ivo Danihelka, Agnieszka Grabska-Barwińska, Sergio Gómez Colmenarejo, Edward Grefenstette, Tiago Ramalho, John Agapiou, Adrià Puigdomènech Badia, Karl Moritz Hermann, Yori Zwols, Georg Ostrovski, Adam Cain, Helen King, Christopher Summerfield, Phil Blunsom, Koray Kavukcuoglu, and Demis Hassabis. [Hybrid computing using a neural network with dynamic external memory](http://www.nature.com/nature/journal/v538/n7626/abs/nature20101.html). *Nature*, 538(7626):471-476. Received 2016 January 5. [PDF](https://www.nature.com/articles/nature20101.epdf?author_access_token=ImTXBI8aWbYxYQ51Plys8NRgN0jAjWel9jnR3ZoTv0MggmpDmwljGswxVdeocYSurJ3hxupzWuRNeGvvXnoO8o4jTJcnAyhGuZzXJ1GEaD-Z7E6X_a9R-xqJ9TfJWBqz). [code](https://github.com/deepmind/dnc).
* 2016 August 10, Daniel Whalen. [Holophrasm: a neural Automated Theorem Prover for higher-order logic](https://arxiv.org/abs/1608.02644). *arXiv:1608.02644*. [code](https://github.com/dwhalen/holophrasm) ([release](https://github.com/dwhalen/holophrasm/releases)).
* 2016 January 27, David Silver, Aja Huang, Chris J. Maddison, Arthur Guez, Laurent Sifre, George van den Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda Panneershelvam, Marc Lanctot, Sander Dieleman, Dominik Grewe, John Nham, Nal Kalchbrenner, Ilya Sutskever, Timothy Lillicrap, Madeleine Leach, Koray Kavukcuoglu, Thore Graepel, and Demis Hassabis. [Mastering the game of Go with deep neural networks and tree search](http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html). *Nature*, 529(7587):484-489. [PDF](https://storage.googleapis.com/deepmind-media/alphago/AlphaGoNaturePaper.pdf).
* 1997 November 15, Sepp Hochreiter and Jürgen Schmidhuber. [Long Short-Term Memory](http://www.mitpressjournals.org/doi/abs/10.1162/neco.1997.9.8.1735). *Neural Computation*, 9:1735-1780.

